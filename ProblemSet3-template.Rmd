---
title: "Analysis on the popular vote of the 2020 American federal election"
author: "Yena Joo, Woolim Kim, Guemin Kim"
date: "Nov 2, 2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
# please install the following package prior to knitting 
# install.packages("kableExtra")
library(tidyverse)
library(lme4)
library(knitr)
library(kableExtra)

# Loading in the cleaned survey Data
survey_data <- read_csv("survey_data.csv")

# exclude responses from those who are not eligible to vote
survey_data <- survey_data %>% filter(vote_intention != "No, I am not eligible to vote")

# Loading in the cleaned census Data
census_data <- read_csv("census_data.csv")

```

### Predictions on the 2020 US Presidential Election based on the voter survey responses.
*Code and data supporting this analysis is available at: https://github.com/Guemin/Problem_Set_3 *

# Model
As the 2020 presidential election of the United States approaches, people across the world are interested in to which candidate the vote of the US citizens will be concentrated, either to Donald Trump or to Joe Biden. Since the election outcome will also affect our community in Canada, we are going to analyze and predict the winner of the popular vote in the 2020 American federal election.  
Using the survey and census data obtained from Democracy Fund + UCLA Nationscape and IPUMS USA, we are going to predict the popular vote outcome of the election. To be more specific, we are going to use two logistic regression models, one for each candidate, and employ a post-stratification technique^[Post-stratification is a technique used in sample survey design to improve the quality of population estimates. In the post-stratification analysis, the population is partitioned into subgroups, and estimates are predicted within the subgroups. Then, the sum of the estimate times the respective population size in each group is calculated, and finally, it is divided by the sum of the total population size. Detailed procedures on post-stratification for our analysis will be shown in the following sub-sections.] with the models.  

In the following sub-sections, we will describe the model specifics, the post-stratification calculation, and the result of the analysis.

## Model specifics

As already mentioned, we will be using the logistic regression models and post-stratification technique with R software to predict the proportions of voters who will vote for either Donald Trump or Joe Biden. Specifically, we will create two models, each for proportions of voters for Trump or Biden, using 6 different variables(age_group, gender, race, education, household_income , and state)^[* age_group is divided into 4 different groups: "18-29 year olds", "30-44 year olds", "45-64 year olds", "65 years and older".  
\    \    \ * gender indicates either "Male" or "Female".  
\    \    \ * race is divided into 5 different categories: "White", "Black", "Native", "Asian", "Other".  
\    \    \ * education is divided into 4 different categories: "Didn't graduate from high school", "High school graduate",   
\    \    \   "Some college or associate degree", "Bachelor's degree or higher".  
\    \    \ * household income consists of 9 categories range from "Less than $14,999" to "$150,000 and over".  
\    \    \ * state indicates abbreviated names of 52 states in the US.].  

Since our response variables, vote_Trump and vote_Biden, are binary(either 'vote for' or 'not vote/not sure'), the logistic regression model is a suitable model to be used. Logistic regression is a mathematical model used to estimate the probability of an event occurring using binary data.  
The logistic regression models we are using are:

$$ log(\frac{p_{i}}{1-p_{i}}) = \beta_0+\beta_1  x_{age\ group} +\beta_2 x_{gender}+\beta_3 x_{race}+\beta_4x_{education}+\beta_5x_{household\ income}+\beta_6x_{state}$$

where $log(\frac{p_{i}}{1-p_{i}})$ represents log odds in each model, and $p_{i}$ is the proportion of voters who will vote for Donald trump or Joe Biden. Similarly, $\beta_0$ represents the intercept, and $\beta_1$,...,  $\beta_6$ indicate the slope parameters of the model. (Detailed descriptions on the x variables can be found in the footnote^[* $x_{age\ group}$ represents one of the four age groups that the respondent is in.  
\    \    \ * $x_{gender}$ indicates the gender of the respondent(either "Male" or "Female").  
\    \    \ * $x_{race}$ indicates the race ethnicity of the respondent.  
\    \    \ * $x_{education}$ indicates the education attainment of the respondent.  
\    \    \ * $x_{household\ income}$ indicates the total pre-tax income of the respondent's household.  
\    \    \ * $x_{state}$ indicates the state in which the respondent is located.]).  



```{r, include=FALSE, warning= FALSE, message=FALSE}
#remove na observations from the survey data
survey_data <- survey_data %>%
  filter(!is.na(age_group), !is.na(gender), !is.na(race), !is.na(education), !is.na(household_income), !is.na(state), !is.na(vote_Trump), !is.na(vote_Biden))
# create logistic regression models for each candidate

#vote for Trump
model_trump <- glm(vote_Trump ~ as.factor(age_group) + as.factor(gender) + as.factor(race) + as.factor(education) + as.factor(household_income) + as.factor(state), data=survey_data, family="binomial")

#voting for Biden
model_biden <- glm(vote_Biden ~ as.factor(age_group) + as.factor(gender) + as.factor(race) + as.factor(education) + as.factor(household_income) + as.factor(state), 
            data=survey_data, family="binomial")
```

**Model Diagnostics**  

With the logistic regression models we created above, we are going to study diagnostics of the models.
First, we need to keep in mind that logistic regressions are well performed under the following assumptions:  

1. Linearity between the log odds and the predictor variables  
   (independent variables should be linearly related to the log odds)  
2. Binary logistic regression requires the response variable to be binary.  
3. Large sample size  
4. Multicollinearity among predictors is not too high  
   (predictor variables should be independent to each other)   
   
In our models, we do not need to worry about the violation of the first assumption since all of our predictor variables are categorical; hence, the categorization of the independent variables is not necessary.  
Similarly, since our response variables, vote_trump and vote_biden are binary, and the size of the survey data is large enough, we can confirm that the second and the third assumptions are also satisfied.  

Now, we want to check if the multicollinearity among predictor variables is not too high. This can be done by calculating the variance inflation factor(VIF) for each predictor variable, which measures the amount of multicollinearity in a set of multiple regression variables; the bigger the VIF, the bigger the multicollinearity is. When the variance inflation factor is greater than 5, the corresponding predictor is said to be highly correlated with other predictors. 
Here are the values of variance inflation factors for predictors in each model:  

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Model diagnostics
## check for multicollinearity of predictors in each model
vif_mod_t <- tibble(model_trump_predictor = c("age_group", "gender", "race", "education",
                                  "household_income", "state"), 
                    VIF = car::vif(model_trump)[,1])
vif_mod_b <- tibble(model_biden_predictor = c("age_group", "gender", "race", "education",
                                  "household_income", "state"), 
                    VIF = car::vif(model_biden)[,1])

kable(
  list(vif_mod_t, vif_mod_b),
  caption = 'VIF models',
  booktabs = TRUE, 
  valign = 't'
)%>%
kable_styling(latex_options = "hold_position")

```
As shown above, VIF values do not exceed 2 for both models for Trump and Biden, which suggest that there is no sign of multicollinearity among predictors. Therefore, it is safe to say that the last assumption is also satisfied.

### Model content  
Prior to the modelings, we mutated variables in the survey data to create new variables that could be used in the analysis. Our response variables, vote_trump and vote_biden are also mutated from a variable named "vote_2020", which provides a name of a candidate that the respondent supports^[vote_trump is 1 when vote_2020 is "Donald Trump", and 0 otherwise; vote_biden is 1 when vote_2020 is "Joe Biden", and 0 otherwise.]. Also, the predictor variables, age_group, gender, race, education, household_income, and state are mutated in the data cleaning process so that the categories in each variable in the survey data match with those in the census data.  
Since only those who are 18 years old or older are eligible to vote, we removed the observations obtained from the respondents who are younger than 18 years old in the data cleaning process. Similarly, we removed the observations of respondents who answered "No, I am not eligible to vote" as vote_intention, since their responses to vote_trump and vote_biden will not count in the actual election. Also, we removed people who are "less than 1 year old" or "90 (90+ in 1980 and 1990)" since their responses are unrealistic or not necessary in our analysis. 

## Post-Stratification 
- Any decisions that your group made should be explained and justified. (For example, are you looking at the proportion of people voting for Trump or Biden? why did you exclude sex in the cell split (practical explanations are acceptable)? etc.)  


Using the log odds estimates, we are going to find vote_Trump and vote_Biden (the proportions of voters each for Donald Trump and Joe Biden) in every possible combination of categories in our predictor variables, age_group, gender, race, education, household income, and state.

In order to estimate the proportions of voters for both Donald Trump and Joe Biden, we are going to perform a post-stratification analysis. In order to use this technique, we need to subdivide the population having similar characteristics into cells. Hence, we are going to create a total of 55,325 cells based on different age groups, gender, race-ethnicity, education attainment, household income, and state.  
Using the logistic regression models presented in the previous sub-section, we will estimate the proportions of voters in each cell for each candidate. Then, we will weigh each estimate within each cell by the respective population size of the cell, and sum those values, and divide that by the entire population size. This process can also be described by the expression:
$$\hat{y}^{ps}\ =\ \frac{\sum N_j*\hat{y_j}}{\sum{N_j}}$$
where $\hat{y_j}$ is the estimate of the probability of voting for either Trump or Biden in each cell, and $N_j$ is the population size of the $j^{th}$ cell based off demographics.

reason for Choice of the variables...

```{r include = FALSE, warning = FALSE, message=FALSE}
# Post-Stratification

###yps for glm Trump 
census_data$logodds_estimate_trump <-
  model_trump %>%
  predict(newdata = census_data)

census_data$estimate_trump <-
  exp(census_data$logodds_estimate_trump)/(1+exp(census_data$logodds_estimate_trump))

#overall prediction for Trump
predict_trump <- 
census_data %>%
  filter(!is.na(estimate_trump))%>%
  mutate(total_vote_prop_trump = estimate_trump*count) %>%
  summarise(total_predict_trump = sum(total_vote_prop_trump)/sum(count))

#using group_by(income)
predict_income_trump <- 
census_data %>%
  filter(!is.na(estimate_trump))%>%
  mutate(vote_prop_trump = estimate_trump*count) %>%
  group_by(household_income)%>%
  summarise(predict_trump= sum(vote_prop_trump)/sum(count))

#using group_by(state)
predict_state_trump <- 
census_data %>%
  filter(!is.na(estimate_trump))%>%
  mutate(vote_prop_trump2 = estimate_trump*count) %>%
  group_by(state)%>%
  summarise(predict_trump2= sum(vote_prop_trump2)/sum(count))

###yps for glm Biden
census_data$logodds_estimate_biden <-
  model_biden %>%
  predict(newdata = census_data)

census_data$estimate_biden <-
  exp(census_data$logodds_estimate_biden)/(1+exp(census_data$logodds_estimate_biden))

#overall prediction for Biden
predict_biden <- 
census_data %>%
  filter(!is.na(estimate_biden))%>%
  mutate(total_vote_prop_biden = estimate_biden*count) %>%
  summarise(total_predict_biden = sum(total_vote_prop_biden)/sum(count))

#using group_by(income)  
predict_income_biden <-
census_data %>%
  filter(!is.na(estimate_biden))%>%
  mutate(vote_prop_biden = estimate_biden*count) %>%
  group_by(household_income)%>%
  summarise(predict_biden = sum(vote_prop_biden)/sum(count))

#using group_by(state)
predict_state_biden <-
census_data %>%
  filter(!is.na(estimate_biden))%>%
  mutate(vote_prop_biden2 = estimate_biden*count) %>%
  group_by(state)%>%
  summarise(predict_biden2 = sum(vote_prop_biden2)/sum(count))

```



# Results

Here you will include all results. This includes descriptive statistics, graphs, figures, tables, and model results. Please ensure that everything is well-formatted and in a report style. You must also provide an explanation of the results in this section. 

Please ensure that everything is well labeled. So if you have multiple histograms and plots, calling them Figure 1, 2, 3, etc. and referencing them as Figure 1, Figure 2, etc. in your report will be expected. The reader should not get lost in a sea of information. Make sure to have the results be clean, well-formatted, and digestible.

In the previous sub-sections, we have created the Logistic Regression models on proportions of voters voting for Donald Trump and Joe Biden using 6 different following variables: age_group, gender, race, education, household_income, and state. Based on the post-stratification analysis we made, our estimation of the proportion of voters voting for Donald Trump is 0.433 (43.3%) and Joe Biden to be 0.394(39.4%). From the result of our estimations, We can predict that Donald Trump is more likely to win the popular vote in the 2020 American federal election.  

```{r echo=FALSE, message=FALSE, warning=FALSE}

#Model results
broom::tidy(model_trump)
broom::tidy(model_biden)
#summary(model_trump)
#summary(model_biden)
#knitr::kables(list(model_trump_tidy, model_biden_tidy))


#Post-Stratification result
## total probability of voting for Trump and Biden
kable(list(predict_trump, predict_biden), caption = "Comparison of predicted estimate between Trump and Biden")%>%
kable_styling(latex_options = "hold_position")
#kables(list(
  #kable(head(predict_trump), "latex", align = "c"), 
  #kable(head(predict_biden), "latex", align = "c")))

#predict_trump
#predict_biden



```
In the summary model for Trump(Figure n), "45-64 year-olds" and "65 years and older" have relatively higher estimates(0.743 and 0.782) which mean for every one-unit increase in the predictor variable, we expect an increase in the log odds, which makes trump more likely to get voted. Similarly, estimates in household_income show that log-odds get lower for people who have relatively low household income (\$15,000 to $24,999). Black race significantly shows low estimates, -1.42192, which lowers the log odds by a significant amount. 
(Figure n) For Biden, as opposed to Trump, shows a high estimate in the black race (0.999153), but has a low estimate in a native race(-0.441602). Also, younger people are more likely to vote, individuals with high income ($150,000 or more) lowers the log odds(-0.046616), but overall well distributed.

- individuals with household_income "less than $14,999" are more likely to vote for Biden over Trump (due to Biden's election promises for lower-income people?)  
- Individuals with a household income " \$100,000 to \$149,999" or "$150,000 or more" show a higher probability of voting for Trump over Biden.

# Discussion

Here you will summarize the previous sections and discuss conclusions drawn from the results. Make sure to elaborate and connect your analysis to the goal of the study.  

Using the survey and census data obtained from Democracy Fund + UCLA Nationscape and IPUMS USA, we have predicted the popular vote outcome of the 2020 presidential election in the USA. In the "Model Specifics" section, Logistic Regression is used to predict who is more likely to be elected for the 2020 presidential election. Explanatory variables used for the logistic regression model are age_group, gender, race, education, household_income, and state.  
Then, by using the post stratification technique, 55,325 cells are made using the census data, based on the 6 variables that were used in the Logistic Regression model, and the probability of voting estimates is estimated for each cell. $\hat{y}^{ps}$ is measured to estimate the proportion of voters in favor of voting for each candidate.   

For an additional estimate, we grouped each cell estimates into states and predicted who is expected to have more. The result shows that Trump is ahead of Biden by 11 counts in the estimate for each state, where Trump is more likely to win in 31 states, and Biden has a higher probability to win in 20 states.  

- The result shows that the estimated value for the proportion of voters voting for Joe Biden is 39.4% and Donald Trump 43.34%.  

- *discuss the result*  

To conclude, based on the estimated proportion of voters in favor of voting for Donald Trump being 0.4334 (43.34%) and expected to win 31 states, we predict that Trump will win the 2020 presidential election.  (......)

## Weaknesses
**improvement**
1. Weakness: Some variables could not be included in the generalized logistic model because either census data or survey data did not include the particular variables. If there is an important variable that could have affected the vote outcome, there might exist an omitted variable bias. (The omitted variables should be correlated with the dependent variable and with the explanatory variables included in the model).  

the Census data used in the analysis is 2018 data, so it might not reflect the most accurate vote outcome. 2020 data is more suitable to analyze more accurate results. Also, people who were underage in 2016, hence not included in the estimate would have the right to vote in 2020.  

Even if a candidate wins in the public vote, he/she can lose the presidency if the electoral college gives the candidate a majority, and vice versa. Therefore, using the popular vote to predict the winner of the presidential election is not the most accurate way to use it.  


## Next Steps

Here you discuss subsequent work to be done after this report. This can include next steps in terms of statistical analysis (perhaps there is a more efficient algorithm available, or perhaps there is a caveat in the data that would allow for some new technique). Future steps should also be specified in terms of the study setting (eg. including a follow-up survey on something, or a subsequent study that would complement the conclusions of your report).  

- With the 2020 census data, we could estimate the proportion of voting for each candidate by state and estimate the winner of each state which would make a more reasonable and realistic prediction of the election.   
- Create a visualization of the results to view the groups of the voting estimates at once.  
- In our future analysis, we can try to analyze the multilevel regression models using Bayes coding techniques.  
- We can compare our prediction and the result of the actual 2020 presidential election.  
*(something about comparing with the actual election results and do a post-hoc analysis (or at least a survey) of how to better improve estimation in future elections.)*

# References
1. Survey data: https://www.voterstudygroup.org/downloads?key=9337162e-e5ef-49d7-96fd-48a5c5dba31c
2. Census data: https://usa.ipums.org/usa-action/extract_requests/summary?
3. Post-Stratification technique: https://www.microsoft.com/en-us/research/wp-content/uploads/2016/04/forecasting-with-nonrepresentative-polls.pdf
4. Logit Regression Assumptions source 1: https://rpubs.com/guptadeepak/logit-assumptions
5. Logit Regression Assumptions source 2: https://www.statisticssolutions.com/wp-content/uploads/wp-post-to-pdf-enhanced-cache/1/assumptions-of-logistic-regression.pdf
6. Variance Inflation Factor(VIF): https://www.statisticshowto.com/variance-inflation-factor/
7. Tables side by side: https://bookdown.org/yihui/rmarkdown-cookbook/kable.html

#Appendix 
```{r echo=FALSE, message=FALSE, warning=FALSE}
## probabilites of voting for Trump and Biden in each state
#predict_state_trump
#predict_state_biden
knitr::kable(list(predict_state_trump, predict_state_biden))
#kables(list(
  #kable(predict_state_trump, "latex", align = "c"), 
  #kable(predict_state_biden, "latex", align = "c")), 
  #caption = "Figure n: ")

## probabilites of voting for Trump and Biden in each household income group
knitr::kable(list(predict_income_trump, predict_income_biden), caption = "Figure n ")
#predict_income_trump
#predict_income_biden
```

